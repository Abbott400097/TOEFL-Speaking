# ETS 官方怎么评 + 接 GitHub 流利度/口音模型耗不耗钱

## ETS 官方是怎么实现的

ETS 对 TOEFL 口语用的是 **自动 + 人工** 两套：

1. **SpeechRater（自动）**  
   - ETS 自研引擎，不对外提供 API。  
   - 会分析：发音、流利度、语速与停顿、词汇与语法等。  
   - 研究里提到用线性回归等模型，结合多类特征（发音、韵律、流利度、词汇/语法、内容与语篇）。  

2. **人工阅卷**  
   - 美国本土认证阅卷员，每天先做校准再打分。  
   - 按 1–4 档评分，看 delivery、language use、topic development。  
   - 最终分数是自动分和人工分的综合（具体权重 ETS 未公开）。  

所以：**官方 = 内部自动引擎 + 人工，没有对外“官方 API”可接**。我们只能尽量用公开的 ETS 档位描述来让 Claude/其他模型按同一标准打分。

---

## 接 GitHub 上的流利度/口音模型耗不耗钱

**不耗“按次付费”的 API 钱，但算力要自己出。**

常见两类用法：

### 1. 本地自己跑（GOPT、fluency_scorer 等）

- **GOPT**（发音/流利度）：依赖 Kaldi、GOP 特征、PyTorch，通常要 **GPU**（例如 1 张 8GB+ 显存）。  
  - 钱 = 电费 + 机器/显卡折旧，或云上开 GPU 实例（按小时计费，不是按“调用次数”）。  
- **fluency_scorer** 等：要准备数据、训练或跑推理，同样要 **CPU/GPU 资源**。  

**结论**：不付“按请求收费”的 API 费，但要么自己有显卡/服务器，要么用云 GPU（按小时/月付费），一次性部署和运维成本比用现成 API 高。

### 2. 用商业发音/流利度 API（第三方）

- 例如 **Speechace**、**Azure Pronunciation Assessment** 等，按次数或按时长计费。  
- 属于“耗钱”的用法，但不用自己搭模型。

---

## 我们当前方案（省 token、不接本地模型）

- **转录**：OpenAI Whisper（你填 `OPENAI_API_KEY`），或你自己的 `TOEFL_TRANSCRIPTION_URL`。  
- **评分**：Claude（你填 `ANTHROPIC_API_KEY`）或 OpenAI，只传 **转录稿 + 时长 + 字数 + WPM**，用简短 ETS 档位说明让模型打 0–4 分 + 一句话理由，**不传音频**，所以耗 token 少。  
- **流利度**：用 **WPM（词/分钟）** 和文本内容让 Claude 顺带判断，不单独接 GitHub 上的流利度/口音模型，所以**不额外产生“跑那些模型”的钱**；若你以后自己接 GOPT 等，把算出来的指标再传给自己的评分接口即可（见 README）。

总结：  
- **ETS 官方** = 自用 SpeechRater + 人工，无对外 API。  
- **接 GitHub 流利度/口音模型** = 不按“每次请求”收费，但要么本地/云 GPU 算力要钱，要么用商业 API 按次/按时长付费；当前项目为了省事省 token 没用这些，只靠 WPM + 转录给 Claude 评。
